# markov_decision_process_program
- Markov Decision Processes are mathematical frameworks used to model a sequential decision-making problem.  At every step in the process, the “agent” must choose an action to take at that step, and then receives a reward after arriving (usually probabilistically) in some new condition, or state, as a result of having taken its chosen action.  The goal of an MDP is to find the optimal action to take from any state in the process in order to maximize long-term rewards.  The goal of this assignment is to implement an MDP, and the value iteration algorithm to solve for the optimal policy.
- When deciding which action to take in a given state, the agent needs to have an approximation of the reward it will get from taking that action in that state.  This is typically done by calculating the expected value of taking the action in the current state. 
